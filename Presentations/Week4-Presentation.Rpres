Floodplain Forest: Week 4 Progress Report
========================================================
author: Sal Balkus, Noah Dean, Makayla McDevitt
date: 6/26/20
autosize: true
css: Week2-Presentation.css
type: section

```{r echo = F}

knitr::opts_chunk$set(warning = F, error = F, message = F, echo = F, include = T, cache = T)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

library(tidyverse)
library(vegclust)
library(ggsci)
library(rpart)
library(rpart.plot)
library(infotheo)

source("classification_procedure.R")

df <- read_csv("clean_data/UMRS_FPF_clean.csv")
labels <- read_csv("clean_data/plot_classification.csv")
df_cols <- left_join(df, labels, by = "PID") %>% select(PID, TR_SP, BasalArea, TreesPerAcre, Type, Label)
df_acsa2 <- filter(df_cols, Type == "ACSA2")

dissim <- read_csv("dissimilarity_matrix.csv")
dissim <- as.matrix(dissim)

plots <- read_csv("clean_data/plots_nonrel.csv")

cluster_h <- hclust(as.dist(dissim), method = "ward.D2")
```

Our Current Objective
========================================================
left: 70%

To construct a hierarchical classification of UMRS forest types that are...
- Ecologically unique
- Useful to foresters
- Suitable for scientific research

<b>Last week</b>, we completed Level 1 using simple rules-based classification and examined various clustering algorithms.

<b>This week</b>, we construct a function for Level 2 classification and visualize results.

***
<img src="Week3-Presentation-figure/unnamed-chunk-18-1.png" height = 100%></img>



Summary statistics from last week: Top 5 Types
========================================================

```{r, out.width = "50%"}
display_dom <- df_cols %>% filter(Label == "Dominant") %>% group_by(Type) %>% summarize(Count = n()) %>% mutate(Percentage = Count / sum(Count)) %>% top_n(5, Count) %>% arrange(desc(Percentage))
display_codom <- df_cols %>% filter(Label == "Codominant") %>% group_by(Type) %>% summarize(Count = n()) %>% mutate(Percentage = Count / sum(Count)) %>% top_n(5, Count) %>% arrange(desc(Percentage))

ggplot(display_dom) + geom_col(aes(x = Type, y = Percentage, fill = Type)) + theme_light() + theme(legend.position = "none", axis.text=element_text(size= 16), 
        axis.title=element_text(size=16), 
        legend.text = element_text(size = 16), 
        legend.title = element_text(size = 16)) + ggtitle("Dominant") + scale_color_jco()
ggplot(display_codom) + geom_col(aes(x = Type, y = Percentage, fill = Type)) + theme_light() + theme(legend.position = "none", 
        axis.title=element_text(size=16), 
        legend.text = element_text(size = 16), 
        legend.title = element_text(size = 16)) + ggtitle("Codominant") + scale_color_jco()
```





Exploration of Ward's Clustering Method
========================================================

How can we define these clusters in a simpler manner?

How can we select the correct number of clusters to use in our definition?

How can we ensure our clusters are ecologically significant?

***

```{r, echo = F, fig.height = 10, fig.width = 10}
cluster_h <- hclust(as.dist(dissim), method = "ward.D2")
plots_acsa2 <- plots %>% filter(Type == "ACSA2")
result <- cutree(cluster_h, k = 3)
plots_acsa2$cluster <- result

ggplot(plots_acsa2) + geom_point(aes(x = log(BA_ACSA2), y = log(TPA_ACSA2), color = as.factor(cluster))) + scale_color_jco() + theme_light() + labs(x = "Basal Area (log)", y = "Trees Per Acre (log)", color = "Cluster") + 
  theme(axis.text=element_text(size= 24), 
        axis.title=element_text(size=24), 
        legend.text = element_text(size = 24), 
        legend.title = element_text(size = 24))

```

Ward's Method with Three Clusters, Silver Maple



Simplifying Clusters: Rule Extraction
========================================================
De Caceres et al (2019) recommends supervised learning for assignment rules to define clusters.

<b>Decision Trees</b> can extract rules to define clusters in a simpler manner
- Input clusters as labels for training data
- Partitions feature space based on simple logic-based rules (greater than or less than)
- Can inform on the number of clusters to use by comparing to clustering


Decision Tree versus Ward's Method
========================================================
```{r, warning = F, out.width = "33%"}
plots_acsa2$cluster <- as.factor(plots_acsa2$cluster)
form <- paste( "cluster ~", paste0(colnames(plots_acsa2)[2:(ncol(plots_acsa2)-3)], collapse = " + "))
tree <- rpart(data = plots_acsa2, formula = form, method = "class", control = rpart.control(maxdepth = 3, cp = 0, minbucket = 6))
p1 <- rpart.plot(tree)
plots_acsa2$tree <- predict(tree, type = "vector")

ggplot(plots_acsa2) + geom_point(aes(x = log(BA_ACSA2), y = log(TPA_ACSA2), color = as.factor(cluster))) + scale_color_jco() + theme_light() + labs(x = "Basal Area (log)", y = "Trees Per Acre (log)", color = "Cluster") + ggtitle("Ward's Method Classification") +
  theme(axis.text=element_text(size= 24), 
        axis.title=element_text(size=24), 
        legend.text = element_text(size = 24), 
        legend.title = element_text(size = 24),
        title = element_text(size = 24))

ggplot(plots_acsa2) + geom_point(aes(x = log(BA_ACSA2), y = log(TPA_ACSA2), color = as.factor(tree))) + scale_color_jco() + theme_light() + labs(x = "Basal Area (log)", y = "Trees Per Acre (log)", color = "Cluster") + ggtitle("Decision Tree Classification") +
  theme(axis.text=element_text(size= 24), 
        axis.title=element_text(size=24), 
        legend.text = element_text(size = 24), 
        legend.title = element_text(size = 24),
        title = element_text(size = 24))


```

Finding the Correct Number of Clusters
========================================================
Take the decision tree classification most similar to the Ward clustering, determined by v-measure

V-measure takes into account cluster homogeneity and completeness, which rely on entropy

<div align = "center">
<img src="Week4-Presentation-figure/v-measure.png" width = 40%></img><br>
<img src="Week4-Presentation-figure/homogeneity.png" width = 40%></img>
<img src="Week4-Presentation-figure/completeness.png" width = 40%></img>
</div>

***
```{r, fig.width = 10, fig.height = 10}
max_clusters <- 10
vmeasures <- vector(length = max_clusters - 1)
for(n in 2:max_clusters){
  cut <- cutree(cluster_h, k = n)
  plots_acsa2$cluster <- cut
  
  tree <- rpart(data = plots_acsa2, formula = form, method = "class", control = rpart.control(maxdepth = ceiling(log(2*n,2)), cp = 0, minbucket = 1))
  plots_acsa2$tree <- predict(tree, plots_acsa2, type = "vector")
  
  h <- 1 - condentropy(plots_acsa2$cluster, plots_acsa2$tree) / entropy(plots_acsa2$cluster)
  c <- 1 - condentropy(plots_acsa2$tree, plots_acsa2$cluster) / entropy(plots_acsa2$tree)
  
  vmeasures[n-1] <- 2 * ((h*c) / (h + c))
}
#higher validity measures are better
wrap <- data.frame(Clusters = (seq(1:9) + 1), V.measure = vmeasures)
ggplot(wrap, mapping = aes(x = Clusters, y = V.measure)) + geom_point() + geom_line() + theme_light() + ggtitle("V-measures for silver maple dominant") + theme(axis.text=element_text(size= 24), 
        axis.title=element_text(size=24), 
        legend.text = element_text(size = 24), 
        legend.title = element_text(size = 24),
        title = element_text(size = 24))
```



Results: Green Ash
========================================================

```{r, out.width = "49%"}
s_df <- load_data("FRPE")
d <- dissimilarity_matrix(s_df)
process <- best_clustering(s_df, d, "FRPE", 20, os = FALSE)
test <- process[[1]]
test_tree <- process[[2]]
rpart.plot(test_tree, cex = 0.5, type = 1)

ggplot(test) + geom_point(aes(x = log(TPA_FRPE), y = log(BA_FRPE), color = as.factor(cluster))) + scale_color_jco() + theme_light()
```

Further Issues to Investigate
========================================================
Imbalanced Class Problem
- Some clusters may have few plots but are ecologically significant
- Potential Solution: oversample classes such that they have the same number of observations as largest class
  - Issue: can result in poor performance, as in Green Ash and Willow clusterings
  
Further Issues to Investigate
========================================================
Ecological Significance
- How can we determine if clusters are two similar?
- Potential Solution: "Multi Response Permutation Procedure" or "Permutational Multivariate Analysis of Variance"    
  - Tests for significant differences between clusters
  - How can we pick out which clusters to merge?

Minimum bin size has large impact on decision tree solution

Mixed Plots
========================================================

```{r}
summary(cars)
```

Non-metric Multidimensional Scaling
========================================================

```{r, echo=FALSE}
plot(cars)
```

References
===========

Cover Image: Forest Landscape Ecology of the Upper Mississippi River Floodplain, United States Geological Survey

V-measure: http://www1.cs.columbia.edu/~amaxwell/pubs/v_measure-emnlp07.pdf